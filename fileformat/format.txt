设计思路如下：

每个服务器每5分钟内收到的消息，写入同一个文件。这样可以减少文件的数目。单种服务每小时12个 每天288, 3个月2万多个，如果有20台服务器，hdfs 上40万个文件。无论是本地文件还是hdfs 的metadata压力应该都不大。
当然服务肯定有很多，文件数可能会非常多，那就减少保存时间。这里只是大致的估计


考虑兼容hdfs， 所以文件只能是append only 只能追加的模式

文件分2个 
文件名设计参考 CAT

meta_data
$service_$timestamp_meta_$serverip

raw_data

$service_$timestamp_raw_$serverip


比如 
服务叫 login
$service = "login" 也可以是数字 比如 1
时间点是  60000
日志服务器ip = "192.168.0.1"

那么 meta日志文件 应该就是 login_60000_meta_192.168.0.1
raw日志文件 应该就是 login_60000_raw_192.168.0.1



基本记录的结构
0-3 timestamp 		    // 消息秒数
4-7 serviceid     		// 这个消息属于service
8-11 messagetypeid 	    // 消息类型id
11-15 datalen            // 数据长度
16-...            被protobuf 序列化以后的结构内容


meta 文件 和raw 文件的关系

首先说raw文件，raw文件记录的原始的数据，也就是序列化以后的tracker 内容

raw文件格式如下

/*  暂时未实现
0-19  前20字节保留
其中
0-8   "wood-raw"      // 保留字
9-10  01              // 版本号，小端格式
11-19 保留0           //
20字节开始   以block 记录结构保留记录
*/

文件格式

block消息的按照顺序连接


block 消息结构

0-3  // 时间秒数
4-7  // 消息长度  假设消息长度为100
8-107 // 基本记录的集合


meta文件


如果顺序扫描raw文件是可以重新生成 meta文件的， meta文件的作用主要是在查找内容的时候帮助快速定位。可以扫描需要的那些块


raw文件的理论长度 无
meta文件理论长度  无


